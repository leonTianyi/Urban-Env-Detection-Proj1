{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1cd147",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API and AWS Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85592c17",
   "metadata": {},
   "source": [
    "In this notebook, you will train and evaluate different models using the [Tensorflow Object Detection API](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/) and [AWS Sagemaker](https://aws.amazon.com/sagemaker/). \n",
    "\n",
    "If you ever feel stuck, you can refer to this [tutorial](https://aws.amazon.com/blogs/machine-learning/training-and-deploying-models-using-tensorflow-2-with-the-object-detection-api-on-amazon-sagemaker/).\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We are using the [Waymo Open Dataset](https://waymo.com/open/) for this project. The dataset has already been exported using the tfrecords format. The files have been created following the format described [here](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#create-tensorflow-records). You can find data stored on [AWS S3](https://aws.amazon.com/s3/), AWS Object Storage. The images are saved with a resolution of 640x640."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc1d114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install tensorflow_io sagemaker -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f55350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "from framework import CustomFramework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde6fd1",
   "metadata": {},
   "source": [
    "Save the IAM role in a variable called `role`. This would be useful when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab6b13b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::598169110696:role/service-role/AmazonSageMaker-ExecutionRole-20230519T214253\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae64e29f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The train and val paths below are public S3 buckets created by Udacity for this project\n",
    "inputs = {'train': 's3://cd2688-object-detection-tf2/train/', \n",
    "        'val': 's3://cd2688-object-detection-tf2/val/'} \n",
    "\n",
    "# Insert path of a folder in your personal S3 bucket to store tensorboard logs.\n",
    "tensorboard_s3_prefix = 's3://object-detection-project-bucket-tianyi/logs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc16a825",
   "metadata": {},
   "source": [
    "## Container\n",
    "\n",
    "To train the model, you will first need to build a [docker](https://www.docker.com/) container with all the dependencies required by the TF Object Detection API. The code below does the following:\n",
    "* clone the Tensorflow models repository\n",
    "* get the exporter and training scripts from the the repository\n",
    "* build the docker image and push it \n",
    "* print the container name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5ac8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# # clone the repo and get the scripts\n",
    "# git clone https://github.com/tensorflow/models.git docker/models\n",
    "\n",
    "# # get model_main and exporter_main files from TF2 Object Detection GitHub repository\n",
    "# cp docker/models/research/object_detection/exporter_main_v2.py source_dir \n",
    "# cp docker/models/research/object_detection/model_main_tf2.py source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dab3f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # build and push the docker image. This code can be commented after being ran once.\n",
    "# # This will take around 10 mins.\n",
    "# image_name = 'tf2-object-detection'\n",
    "# !sh ./docker/build_and_push.sh $image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b3562",
   "metadata": {},
   "source": [
    "To verify that the image was correctly pushed to the [Elastic Container Registry](https://aws.amazon.com/ecr/), you can look at it in the AWS webapp. For example, below you can see that three different images have been pushed to ECR. You should only see one, called `tf2-object-detection`.\n",
    "![ECR Example](../data/example_ecr.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0310b6a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598169110696.dkr.ecr.us-east-1.amazonaws.com/tf2-object-detection:20230520165739\n"
     ]
    }
   ],
   "source": [
    "# display the container name\n",
    "with open (os.path.join('docker', 'ecr_image_fullname.txt'), 'r') as f:\n",
    "    container = f.readlines()[0][:-1]\n",
    "\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2a754",
   "metadata": {},
   "source": [
    "## Pre-trained model from model zoo\n",
    "\n",
    "As often, we are not training from scratch and we will be using a pretrained model from the TF Object Detection model zoo. You can find pretrained checkpoints [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Because your time is limited for this project, we recommend to only experiment with the following models:\n",
    "* SSD MobileNet V2 FPNLite 640x640\t\n",
    "* SSD ResNet50 V1 FPN 640x640 (RetinaNet50)\t\n",
    "* Faster R-CNN ResNet50 V1 640x640\t\n",
    "* EfficientDet D1 640x640\t\n",
    "* Faster R-CNN ResNet152 V1 640x640\t\n",
    "\n",
    "In the code below, the EfficientDet D1 model is downloaded and extracted. This code should be ajusted if you were to experiment with other architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3f0be-f16d-4ac3-8ad1-e60eec1b9839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c507a-2736-473e-8735-d9c1d0dd5935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c4b1d46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/tmp/checkpoint’: File exists\n",
      "mkdir: cannot create directory ‘source_dir/checkpoint’: File exists\n",
      "--2023-05-20 18:38:51--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.111.128, 2607:f8b0:4004:c07::80\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.111.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20518283 (20M) [application/x-tar]\n",
      "Saving to: ‘/tmp/efficientdet.tar.gz’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 11.6M 2s\n",
      "    50K .......... .......... .......... .......... ..........  0% 23.9M 1s\n",
      "   100K .......... .......... .......... .......... ..........  0% 24.2M 1s\n",
      "   150K .......... .......... .......... .......... ..........  0% 40.7M 1s\n",
      "   200K .......... .......... .......... .......... ..........  1% 57.7M 1s\n",
      "   250K .......... .......... .......... .......... ..........  1% 90.4M 1s\n",
      "   300K .......... .......... .......... .......... ..........  1% 66.0M 1s\n",
      "   350K .......... .......... .......... .......... ..........  1% 78.5M 1s\n",
      "   400K .......... .......... .......... .......... ..........  2%  168M 1s\n",
      "   450K .......... .......... .......... .......... ..........  2%  128M 1s\n",
      "   500K .......... .......... .......... .......... ..........  2%  153M 0s\n",
      "   550K .......... .......... .......... .......... ..........  2%  102M 0s\n",
      "   600K .......... .......... .......... .......... ..........  3% 60.7M 0s\n",
      "   650K .......... .......... .......... .......... ..........  3%  146M 0s\n",
      "   700K .......... .......... .......... .......... ..........  3%  126M 0s\n",
      "   750K .......... .......... .......... .......... ..........  3%  149M 0s\n",
      "   800K .......... .......... .......... .......... ..........  4%  140M 0s\n",
      "   850K .......... .......... .......... .......... ..........  4%  138M 0s\n",
      "   900K .......... .......... .......... .......... ..........  4%  138M 0s\n",
      "   950K .......... .......... .......... .......... ..........  4% 67.4M 0s\n",
      "  1000K .......... .......... .......... .......... ..........  5%  110M 0s\n",
      "  1050K .......... .......... .......... .......... ..........  5%  138M 0s\n",
      "  1100K .......... .......... .......... .......... ..........  5%  199M 0s\n",
      "  1150K .......... .......... .......... .......... ..........  5%  130M 0s\n",
      "  1200K .......... .......... .......... .......... ..........  6% 71.7M 0s\n",
      "  1250K .......... .......... .......... .......... ..........  6%  171M 0s\n",
      "  1300K .......... .......... .......... .......... ..........  6%  177M 0s\n",
      "  1350K .......... .......... .......... .......... ..........  6%  163M 0s\n",
      "  1400K .......... .......... .......... .......... ..........  7%  108M 0s\n",
      "  1450K .......... .......... .......... .......... ..........  7%  190M 0s\n",
      "  1500K .......... .......... .......... .......... ..........  7% 78.6M 0s\n",
      "  1550K .......... .......... .......... .......... ..........  7%  133M 0s\n",
      "  1600K .......... .......... .......... .......... ..........  8%  184M 0s\n",
      "  1650K .......... .......... .......... .......... ..........  8%  166M 0s\n",
      "  1700K .......... .......... .......... .......... ..........  8%  228M 0s\n",
      "  1750K .......... .......... .......... .......... ..........  8%  278M 0s\n",
      "  1800K .......... .......... .......... .......... ..........  9%  150M 0s\n",
      "  1850K .......... .......... .......... .......... ..........  9%  147M 0s\n",
      "  1900K .......... .......... .......... .......... ..........  9%  292M 0s\n",
      "  1950K .......... .......... .......... .......... ..........  9%  154M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 10%  204M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 10%  305M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 10%  105M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 10%  148M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 11%  163M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 11%  183M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 11%  201M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 11%  121M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 12%  142M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 12% 74.2M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 12%  303M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 12%  268M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 13%  313M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 13%  318M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 13%  297M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 13%  280M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 14%  295M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 14%  289M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 14%  318M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 14%  225M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 15%  318M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 15%  312M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 15%  324M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 15%  279M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 16%  316M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 16%  320M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 16%  320M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 16%  203M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 17%  320M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 17%  320M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 17%  318M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 17%  261M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 18%  323M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 18%  120M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 18%  285M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 18%  266M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 19%  300M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 19%  320M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 19%  326M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 19%  239M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 20%  294M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 20% 1.04M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 20%  112M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 20%  135M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 21%  112M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 21%  116M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 21%  129M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 21%  147M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 22%  173M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 22% 93.3M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 22%  110M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 22%  131M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 23%  115M 0s\n",
      "  4650K .......... .......... .......... .......... .......... 23%  131M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 23%  140M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 23%  160M 0s\n",
      "  4800K .......... .......... .......... .......... .......... 24%  138M 0s\n",
      "  4850K .......... .......... .......... .......... .......... 24% 43.0M 0s\n",
      "  4900K .......... .......... .......... .......... .......... 24% 79.5M 0s\n",
      "  4950K .......... .......... .......... .......... .......... 24%  135M 0s\n",
      "  5000K .......... .......... .......... .......... .......... 25%  118M 0s\n",
      "  5050K .......... .......... .......... .......... .......... 25% 90.3M 0s\n",
      "  5100K .......... .......... .......... .......... .......... 25%  134M 0s\n",
      "  5150K .......... .......... .......... .......... .......... 25%  103M 0s\n",
      "  5200K .......... .......... .......... .......... .......... 26%  113M 0s\n",
      "  5250K .......... .......... .......... .......... .......... 26%  162M 0s\n",
      "  5300K .......... .......... .......... .......... .......... 26%  111M 0s\n",
      "  5350K .......... .......... .......... .......... .......... 26%  147M 0s\n",
      "  5400K .......... .......... .......... .......... .......... 27%  143M 0s\n",
      "  5450K .......... .......... .......... .......... .......... 27%  332M 0s\n",
      "  5500K .......... .......... .......... .......... .......... 27%  324M 0s\n",
      "  5550K .......... .......... .......... .......... .......... 27%  318M 0s\n",
      "  5600K .......... .......... .......... .......... .......... 28%  108M 0s\n",
      "  5650K .......... .......... .......... .......... .......... 28%  319M 0s\n",
      "  5700K .......... .......... .......... .......... .......... 28%  122M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 28%  341M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 29%  328M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 29%  384M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 29%  379M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 29%  321M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 30%  269M 0s\n",
      "  6050K .......... .......... .......... .......... .......... 30%  314M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 30%  320M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 30%  322M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 31%  259M 0s\n",
      "  6250K .......... .......... .......... .......... .......... 31%  235M 0s\n",
      "  6300K .......... .......... .......... .......... .......... 31%  325M 0s\n",
      "  6350K .......... .......... .......... .......... .......... 31%  332M 0s\n",
      "  6400K .......... .......... .......... .......... .......... 32%  283M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 32% 92.0M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 32%  321M 0s\n",
      "  6550K .......... .......... .......... .......... .......... 32%  333M 0s\n",
      "  6600K .......... .......... .......... .......... .......... 33%  283M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 33%  322M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 33%  328M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 33%  326M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 34%  280M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 34%  258M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 34%  207M 0s\n",
      "  6950K .......... .......... .......... .......... .......... 34%  298M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 35%  279M 0s\n",
      "  7050K .......... .......... .......... .......... .......... 35%  313M 0s\n",
      "  7100K .......... .......... .......... .......... .......... 35%  301M 0s\n",
      "  7150K .......... .......... .......... .......... .......... 35%  327M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 36%  286M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 36%  319M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 36%  196M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 36%  235M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 37%  267M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 37%  312M 0s\n",
      "  7500K .......... .......... .......... .......... .......... 37%  246M 0s\n",
      "  7550K .......... .......... .......... .......... .......... 37%  245M 0s\n",
      "  7600K .......... .......... .......... .......... .......... 38%  264M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 38%  134M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 38%  323M 0s\n",
      "  7750K .......... .......... .......... .......... .......... 38%  323M 0s\n",
      "  7800K .......... .......... .......... .......... .......... 39%  274M 0s\n",
      "  7850K .......... .......... .......... .......... .......... 39%  331M 0s\n",
      "  7900K .......... .......... .......... .......... .......... 39%  328M 0s\n",
      "  7950K .......... .......... .......... .......... .......... 39%  268M 0s\n",
      "  8000K .......... .......... .......... .......... .......... 40%  287M 0s\n",
      "  8050K .......... .......... .......... .......... .......... 40%  334M 0s\n",
      "  8100K .......... .......... .......... .......... .......... 40%  299M 0s\n",
      "  8150K .......... .......... .......... .......... .......... 40% 1.93M 0s\n",
      "  8200K .......... .......... .......... .......... .......... 41%  233M 0s\n",
      "  8250K .......... .......... .......... .......... .......... 41%  292M 0s\n",
      "  8300K .......... .......... .......... .......... .......... 41%  336M 0s\n",
      "  8350K .......... .......... .......... .......... .......... 41%  175M 0s\n",
      "  8400K .......... .......... .......... .......... .......... 42%  279M 0s\n",
      "  8450K .......... .......... .......... .......... .......... 42%  337M 0s\n",
      "  8500K .......... .......... .......... .......... .......... 42%  361M 0s\n",
      "  8550K .......... .......... .......... .......... .......... 42%  159M 0s\n",
      "  8600K .......... .......... .......... .......... .......... 43%  272M 0s\n",
      "  8650K .......... .......... .......... .......... .......... 43%  302M 0s\n",
      "  8700K .......... .......... .......... .......... .......... 43%  174M 0s\n",
      "  8750K .......... .......... .......... .......... .......... 43%  272M 0s\n",
      "  8800K .......... .......... .......... .......... .......... 44%  245M 0s\n",
      "  8850K .......... .......... .......... .......... .......... 44%  251M 0s\n",
      "  8900K .......... .......... .......... .......... .......... 44%  311M 0s\n",
      "  8950K .......... .......... .......... .......... .......... 44%  280M 0s\n",
      "  9000K .......... .......... .......... .......... .......... 45%  229M 0s\n",
      "  9050K .......... .......... .......... .......... .......... 45%  269M 0s\n",
      "  9100K .......... .......... .......... .......... .......... 45%  259M 0s\n",
      "  9150K .......... .......... .......... .......... .......... 45%  269M 0s\n",
      "  9200K .......... .......... .......... .......... .......... 46%  251M 0s\n",
      "  9250K .......... .......... .......... .......... .......... 46%  290M 0s\n",
      "  9300K .......... .......... .......... .......... .......... 46%  254M 0s\n",
      "  9350K .......... .......... .......... .......... .......... 46%  192M 0s\n",
      "  9400K .......... .......... .......... .......... .......... 47%  238M 0s\n",
      "  9450K .......... .......... .......... .......... .......... 47%  267M 0s\n",
      "  9500K .......... .......... .......... .......... .......... 47%  334M 0s\n",
      "  9550K .......... .......... .......... .......... .......... 47%  302M 0s\n",
      "  9600K .......... .......... .......... .......... .......... 48%  230M 0s\n",
      "  9650K .......... .......... .......... .......... .......... 48% 28.2M 0s\n",
      "  9700K .......... .......... .......... .......... .......... 48%  305M 0s\n",
      "  9750K .......... .......... .......... .......... .......... 48% 52.4M 0s\n",
      "  9800K .......... .......... .......... .......... .......... 49%  161M 0s\n",
      "  9850K .......... .......... .......... .......... .......... 49%  305M 0s\n",
      "  9900K .......... .......... .......... .......... .......... 49%  297M 0s\n",
      "  9950K .......... .......... .......... .......... .......... 49%  304M 0s\n",
      " 10000K .......... .......... .......... .......... .......... 50%  261M 0s\n",
      " 10050K .......... .......... .......... .......... .......... 50%  298M 0s\n",
      " 10100K .......... .......... .......... .......... .......... 50% 58.5M 0s\n",
      " 10150K .......... .......... .......... .......... .......... 50%  292M 0s\n",
      " 10200K .......... .......... .......... .......... .......... 51%  205M 0s\n",
      " 10250K .......... .......... .......... .......... .......... 51%  356M 0s\n",
      " 10300K .......... .......... .......... .......... .......... 51%  335M 0s\n",
      " 10350K .......... .......... .......... .......... .......... 51%  304M 0s\n",
      " 10400K .......... .......... .......... .......... .......... 52%  324M 0s\n",
      " 10450K .......... .......... .......... .......... .......... 52%  360M 0s\n",
      " 10500K .......... .......... .......... .......... .......... 52%  328M 0s\n",
      " 10550K .......... .......... .......... .......... .......... 52%  314M 0s\n",
      " 10600K .......... .......... .......... .......... .......... 53%  310M 0s\n",
      " 10650K .......... .......... .......... .......... .......... 53%  359M 0s\n",
      " 10700K .......... .......... .......... .......... .......... 53% 67.8M 0s\n",
      " 10750K .......... .......... .......... .......... .......... 53%  330M 0s\n",
      " 10800K .......... .......... .......... .......... .......... 54%  311M 0s\n",
      " 10850K .......... .......... .......... .......... .......... 54%  289M 0s\n",
      " 10900K .......... .......... .......... .......... .......... 54%  309M 0s\n",
      " 10950K .......... .......... .......... .......... .......... 54%  345M 0s\n",
      " 11000K .......... .......... .......... .......... .......... 55%  170M 0s\n",
      " 11050K .......... .......... .......... .......... .......... 55%  348M 0s\n",
      " 11100K .......... .......... .......... .......... .......... 55%  255M 0s\n",
      " 11150K .......... .......... .......... .......... .......... 55%  370M 0s\n",
      " 11200K .......... .......... .......... .......... .......... 56%  301M 0s\n",
      " 11250K .......... .......... .......... .......... .......... 56% 89.4M 0s\n",
      " 11300K .......... .......... .......... .......... .......... 56%  316M 0s\n",
      " 11350K .......... .......... .......... .......... .......... 56%  209M 0s\n",
      " 11400K .......... .......... .......... .......... .......... 57%  232M 0s\n",
      " 11450K .......... .......... .......... .......... .......... 57%  326M 0s\n",
      " 11500K .......... .......... .......... .......... .......... 57%  321M 0s\n",
      " 11550K .......... .......... .......... .......... .......... 57%  307M 0s\n",
      " 11600K .......... .......... .......... .......... .......... 58%  203M 0s\n",
      " 11650K .......... .......... .......... .......... .......... 58%  176M 0s\n",
      " 11700K .......... .......... .......... .......... .......... 58% 80.6M 0s\n",
      " 11750K .......... .......... .......... .......... .......... 58% 29.1M 0s\n",
      " 11800K .......... .......... .......... .......... .......... 59%  155M 0s\n",
      " 11850K .......... .......... .......... .......... .......... 59%  141M 0s\n",
      " 11900K .......... .......... .......... .......... .......... 59%  329M 0s\n",
      " 11950K .......... .......... .......... .......... .......... 59%  308M 0s\n",
      " 12000K .......... .......... .......... .......... .......... 60%  266M 0s\n",
      " 12050K .......... .......... .......... .......... .......... 60%  279M 0s\n",
      " 12100K .......... .......... .......... .......... .......... 60%  241M 0s\n",
      " 12150K .......... .......... .......... .......... .......... 60%  228M 0s\n",
      " 12200K .......... .......... .......... .......... .......... 61%  111M 0s\n",
      " 12250K .......... .......... .......... .......... .......... 61%  254M 0s\n",
      " 12300K .......... .......... .......... .......... .......... 61%  308M 0s\n",
      " 12350K .......... .......... .......... .......... .......... 61%  260M 0s\n",
      " 12400K .......... .......... .......... .......... .......... 62%  227M 0s\n",
      " 12450K .......... .......... .......... .......... .......... 62%  252M 0s\n",
      " 12500K .......... .......... .......... .......... .......... 62%  148M 0s\n",
      " 12550K .......... .......... .......... .......... .......... 62%  308M 0s\n",
      " 12600K .......... .......... .......... .......... .......... 63%  174M 0s\n",
      " 12650K .......... .......... .......... .......... .......... 63%  313M 0s\n",
      " 12700K .......... .......... .......... .......... .......... 63%  318M 0s\n",
      " 12750K .......... .......... .......... .......... .......... 63%  297M 0s\n",
      " 12800K .......... .......... .......... .......... .......... 64%  179M 0s\n",
      " 12850K .......... .......... .......... .......... .......... 64%  282M 0s\n",
      " 12900K .......... .......... .......... .......... .......... 64%  188M 0s\n",
      " 12950K .......... .......... .......... .......... .......... 64%  315M 0s\n",
      " 13000K .......... .......... .......... .......... .......... 65%  244M 0s\n",
      " 13050K .......... .......... .......... .......... .......... 65%  326M 0s\n",
      " 13100K .......... .......... .......... .......... .......... 65%  253M 0s\n",
      " 13150K .......... .......... .......... .......... .......... 65%  326M 0s\n",
      " 13200K .......... .......... .......... .......... .......... 66%  254M 0s\n",
      " 13250K .......... .......... .......... .......... .......... 66%  266M 0s\n",
      " 13300K .......... .......... .......... .......... .......... 66%  308M 0s\n",
      " 13350K .......... .......... .......... .......... .......... 66%  319M 0s\n",
      " 13400K .......... .......... .......... .......... .......... 67%  271M 0s\n",
      " 13450K .......... .......... .......... .......... .......... 67%  105M 0s\n",
      " 13500K .......... .......... .......... .......... .......... 67%  283M 0s\n",
      " 13550K .......... .......... .......... .......... .......... 67%  319M 0s\n",
      " 13600K .......... .......... .......... .......... .......... 68%  282M 0s\n",
      " 13650K .......... .......... .......... .......... .......... 68%  338M 0s\n",
      " 13700K .......... .......... .......... .......... .......... 68%  321M 0s\n",
      " 13750K .......... .......... .......... .......... .......... 68%  338M 0s\n",
      " 13800K .......... .......... .......... .......... .......... 69%  276M 0s\n",
      " 13850K .......... .......... .......... .......... .......... 69%  355M 0s\n",
      " 13900K .......... .......... .......... .......... .......... 69%  325M 0s\n",
      " 13950K .......... .......... .......... .......... .......... 69%  309M 0s\n",
      " 14000K .......... .......... .......... .......... .......... 70%  294M 0s\n",
      " 14050K .......... .......... .......... .......... .......... 70%  325M 0s\n",
      " 14100K .......... .......... .......... .......... .......... 70%  310M 0s\n",
      " 14150K .......... .......... .......... .......... .......... 70%  311M 0s\n",
      " 14200K .......... .......... .......... .......... .......... 71%  262M 0s\n",
      " 14250K .......... .......... .......... .......... .......... 71%  254M 0s\n",
      " 14300K .......... .......... .......... .......... .......... 71%  291M 0s\n",
      " 14350K .......... .......... .......... .......... .......... 71%  342M 0s\n",
      " 14400K .......... .......... .......... .......... .......... 72%  310M 0s\n",
      " 14450K .......... .......... .......... .......... .......... 72%  280M 0s\n",
      " 14500K .......... .......... .......... .......... .......... 72%  263M 0s\n",
      " 14550K .......... .......... .......... .......... .......... 72%  262M 0s\n",
      " 14600K .......... .......... .......... .......... .......... 73%  269M 0s\n",
      " 14650K .......... .......... .......... .......... .......... 73%  244M 0s\n",
      " 14700K .......... .......... .......... .......... .......... 73%  247M 0s\n",
      " 14750K .......... .......... .......... .......... .......... 73%  287M 0s\n",
      " 14800K .......... .......... .......... .......... .......... 74%  254M 0s\n",
      " 14850K .......... .......... .......... .......... .......... 74%  301M 0s\n",
      " 14900K .......... .......... .......... .......... .......... 74%  294M 0s\n",
      " 14950K .......... .......... .......... .......... .......... 74%  303M 0s\n",
      " 15000K .......... .......... .......... .......... .......... 75%  255M 0s\n",
      " 15050K .......... .......... .......... .......... .......... 75%  286M 0s\n",
      " 15100K .......... .......... .......... .......... .......... 75%  261M 0s\n",
      " 15150K .......... .......... .......... .......... .......... 75%  305M 0s\n",
      " 15200K .......... .......... .......... .......... .......... 76%  226M 0s\n",
      " 15250K .......... .......... .......... .......... .......... 76%  132M 0s\n",
      " 15300K .......... .......... .......... .......... .......... 76%  259M 0s\n",
      " 15350K .......... .......... .......... .......... .......... 76%  122M 0s\n",
      " 15400K .......... .......... .......... .......... .......... 77% 59.7M 0s\n",
      " 15450K .......... .......... .......... .......... .......... 77%  233M 0s\n",
      " 15500K .......... .......... .......... .......... .......... 77%  201M 0s\n",
      " 15550K .......... .......... .......... .......... .......... 77% 19.6M 0s\n",
      " 15600K .......... .......... .......... .......... .......... 78%  281M 0s\n",
      " 15650K .......... .......... .......... .......... .......... 78%  357M 0s\n",
      " 15700K .......... .......... .......... .......... .......... 78%  287M 0s\n",
      " 15750K .......... .......... .......... .......... .......... 78%  321M 0s\n",
      " 15800K .......... .......... .......... .......... .......... 79%  240M 0s\n",
      " 15850K .......... .......... .......... .......... .......... 79%  270M 0s\n",
      " 15900K .......... .......... .......... .......... .......... 79%  320M 0s\n",
      " 15950K .......... .......... .......... .......... .......... 79% 47.4M 0s\n",
      " 16000K .......... .......... .......... .......... .......... 80%  254M 0s\n",
      " 16050K .......... .......... .......... .......... .......... 80%  241M 0s\n",
      " 16100K .......... .......... .......... .......... .......... 80%  295M 0s\n",
      " 16150K .......... .......... .......... .......... .......... 80%  314M 0s\n",
      " 16200K .......... .......... .......... .......... .......... 81%  197M 0s\n",
      " 16250K .......... .......... .......... .......... .......... 81%  332M 0s\n",
      " 16300K .......... .......... .......... .......... .......... 81%  283M 0s\n",
      " 16350K .......... .......... .......... .......... .......... 81%  331M 0s\n",
      " 16400K .......... .......... .......... .......... .......... 82%  233M 0s\n",
      " 16450K .......... .......... .......... .......... .......... 82%  280M 0s\n",
      " 16500K .......... .......... .......... .......... .......... 82%  420M 0s\n",
      " 16550K .......... .......... .......... .......... .......... 82%  484M 0s\n",
      " 16600K .......... .......... .......... .......... .......... 83% 92.8M 0s\n",
      " 16650K .......... .......... .......... .......... .......... 83%  432M 0s\n",
      " 16700K .......... .......... .......... .......... .......... 83%  483M 0s\n",
      " 16750K .......... .......... .......... .......... .......... 83%  372M 0s\n",
      " 16800K .......... .......... .......... .......... .......... 84%  318M 0s\n",
      " 16850K .......... .......... .......... .......... .......... 84%  141M 0s\n",
      " 16900K .......... .......... .......... .......... .......... 84% 91.9M 0s\n",
      " 16950K .......... .......... .......... .......... .......... 84%  223M 0s\n",
      " 17000K .......... .......... .......... .......... .......... 85%  173M 0s\n",
      " 17050K .......... .......... .......... .......... .......... 85% 46.4M 0s\n",
      " 17100K .......... .......... .......... .......... .......... 85%  175M 0s\n",
      " 17150K .......... .......... .......... .......... .......... 85%  177M 0s\n",
      " 17200K .......... .......... .......... .......... .......... 86%  178M 0s\n",
      " 17250K .......... .......... .......... .......... .......... 86%  224M 0s\n",
      " 17300K .......... .......... .......... .......... .......... 86%  176M 0s\n",
      " 17350K .......... .......... .......... .......... .......... 86% 65.7M 0s\n",
      " 17400K .......... .......... .......... .......... .......... 87% 75.7M 0s\n",
      " 17450K .......... .......... .......... .......... .......... 87%  143M 0s\n",
      " 17500K .......... .......... .......... .......... .......... 87%  191M 0s\n",
      " 17550K .......... .......... .......... .......... .......... 87%  234M 0s\n",
      " 17600K .......... .......... .......... .......... .......... 88%  189M 0s\n",
      " 17650K .......... .......... .......... .......... .......... 88%  274M 0s\n",
      " 17700K .......... .......... .......... .......... .......... 88% 87.1M 0s\n",
      " 17750K .......... .......... .......... .......... .......... 88%  292M 0s\n",
      " 17800K .......... .......... .......... .......... .......... 89%  202M 0s\n",
      " 17850K .......... .......... .......... .......... .......... 89%  290M 0s\n",
      " 17900K .......... .......... .......... .......... .......... 89%  283M 0s\n",
      " 17950K .......... .......... .......... .......... .......... 89%  270M 0s\n",
      " 18000K .......... .......... .......... .......... .......... 90%  200M 0s\n",
      " 18050K .......... .......... .......... .......... .......... 90%  299M 0s\n",
      " 18100K .......... .......... .......... .......... .......... 90%  255M 0s\n",
      " 18150K .......... .......... .......... .......... .......... 90%  186M 0s\n",
      " 18200K .......... .......... .......... .......... .......... 91%  253M 0s\n",
      " 18250K .......... .......... .......... .......... .......... 91%  243M 0s\n",
      " 18300K .......... .......... .......... .......... .......... 91%  254M 0s\n",
      " 18350K .......... .......... .......... .......... .......... 91%  275M 0s\n",
      " 18400K .......... .......... .......... .......... .......... 92%  207M 0s\n",
      " 18450K .......... .......... .......... .......... .......... 92%  313M 0s\n",
      " 18500K .......... .......... .......... .......... .......... 92%  286M 0s\n",
      " 18550K .......... .......... .......... .......... .......... 92%  279M 0s\n",
      " 18600K .......... .......... .......... .......... .......... 93%  229M 0s\n",
      " 18650K .......... .......... .......... .......... .......... 93%  183M 0s\n",
      " 18700K .......... .......... .......... .......... .......... 93%  356M 0s\n",
      " 18750K .......... .......... .......... .......... .......... 93%  348M 0s\n",
      " 18800K .......... .......... .......... .......... .......... 94%  329M 0s\n",
      " 18850K .......... .......... .......... .......... .......... 94%  282M 0s\n",
      " 18900K .......... .......... .......... .......... .......... 94%  328M 0s\n",
      " 18950K .......... .......... .......... .......... .......... 94%  411M 0s\n",
      " 19000K .......... .......... .......... .......... .......... 95%  312M 0s\n",
      " 19050K .......... .......... .......... .......... .......... 95%  402M 0s\n",
      " 19100K .......... .......... .......... .......... .......... 95%  405M 0s\n",
      " 19150K .......... .......... .......... .......... .......... 95%  338M 0s\n",
      " 19200K .......... .......... .......... .......... .......... 96%  317M 0s\n",
      " 19250K .......... .......... .......... .......... .......... 96%  394M 0s\n",
      " 19300K .......... .......... .......... .......... .......... 96%  400M 0s\n",
      " 19350K .......... .......... .......... .......... .......... 96%  360M 0s\n",
      " 19400K .......... .......... .......... .......... .......... 97%  326M 0s\n",
      " 19450K .......... .......... .......... .......... .......... 97%  390M 0s\n",
      " 19500K .......... .......... .......... .......... .......... 97%  371M 0s\n",
      " 19550K .......... .......... .......... .......... .......... 97%  289M 0s\n",
      " 19600K .......... .......... .......... .......... .......... 98%  338M 0s\n",
      " 19650K .......... .......... .......... .......... .......... 98%  380M 0s\n",
      " 19700K .......... .......... .......... .......... .......... 98%  359M 0s\n",
      " 19750K .......... .......... .......... .......... .......... 98%  405M 0s\n",
      " 19800K .......... .......... .......... .......... .......... 99%  289M 0s\n",
      " 19850K .......... .......... .......... .......... .......... 99%  359M 0s\n",
      " 19900K .......... .......... .......... .......... .......... 99%  405M 0s\n",
      " 19950K .......... .......... .......... .......... .......... 99%  391M 0s\n",
      " 20000K .......... .......... .......... .......              100%  271M=0.2s\n",
      "\n",
      "2023-05-20 18:38:51 (107 MB/s) - ‘/tmp/efficientdet.tar.gz’ saved [20518283/20518283]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir /tmp/checkpoint\n",
    "mkdir source_dir/checkpoint\n",
    "# wget -O /tmp/efficientdet.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\n",
    "wget -O /tmp/efficientdet.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
    "# tar -zxvf /tmp/efficientdet.tar.gz --strip-components 2 --directory source_dir/checkpoint efficientdet_d1_coco17_tpu-32/checkpoint\n",
    "tar -zxvf /tmp/efficientdet.tar.gz --strip-components 2 --directory source_dir/checkpoint ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e04a98",
   "metadata": {},
   "source": [
    "## Edit pipeline.config file\n",
    "\n",
    "The [`pipeline.config`](source_dir/pipeline.config) in the `source_dir` folder should be updated when you experiment with different models. The different config files are available [here](https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2).\n",
    "\n",
    ">Note: The provided `pipeline.config` file works well with the `EfficientDet` model. You would need to modify it when working with other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47483545",
   "metadata": {},
   "source": [
    "## Launch Training Job\n",
    "\n",
    "Now that we have a dataset, a docker image and some pretrained model weights, we can launch the training job. To do so, we create a [Sagemaker Framework](https://sagemaker.readthedocs.io/en/stable/frameworks/index.html), where we indicate the container name, name of the config file, number of training steps etc.\n",
    "\n",
    "The `run_training.sh` script does the following:\n",
    "* train the model for `num_train_steps` \n",
    "* evaluate over the val dataset\n",
    "* export the model\n",
    "\n",
    "Different metrics will be displayed during the evaluation phase, including the mean average precision. These metrics can be used to quantify your model performances and compare over the different iterations.\n",
    "\n",
    "You can also monitor the training progress by navigating to **Training -> Training Jobs** from the Amazon Sagemaker dashboard in the Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c7175cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tf2-object-detection-MobNetV2-2023-05-20-18-48-10-693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-20 18:48:12 Starting - Starting the training job...\n",
      "2023-05-20 18:48:27 Starting - Preparing the instances for training......\n",
      "2023-05-20 18:49:37 Downloading - Downloading input data...\n",
      "2023-05-20 18:50:02 Training - Downloading the training image...............\n",
      "2023-05-20 18:52:27 Training - Training image download completed. Training in progress...\u001b[34m2023-05-20 18:52:52,979 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-05-20 18:52:52,981 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-05-20 18:52:52,997 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-05-20 18:52:52,999 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-05-20 18:52:53,014 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-05-20 18:52:53,016 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-05-20 18:52:53,029 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m4.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"/opt/training\",\n",
      "        \"num_train_steps\": \"1000\",\n",
      "        \"pipeline_config_path\": \"pipeline.config\",\n",
      "        \"sample_1_of_n_eval_examples\": \"1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m4.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"tf2-object-detection-MobNetV2-2023-05-20-18-48-10-693\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-598169110696/tf2-object-detection-MobNetV2-2023-05-20-18-48-10-693/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_training.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m4.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m4.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_training.sh\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"/opt/training\",\"num_train_steps\":\"1000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m4.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-598169110696/tf2-object-detection-MobNetV2-2023-05-20-18-48-10-693/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m4.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"/opt/training\",\"num_train_steps\":\"1000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"tf2-object-detection-MobNetV2-2023-05-20-18-48-10-693\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-598169110696/tf2-object-detection-MobNetV2-2023-05-20-18-48-10-693/source/sourcedir.tar.gz\",\"module_name\":\"run_training.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_training.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"/opt/training\",\"--num_train_steps\",\"1000\",\"--pipeline_config_path\",\"pipeline.config\",\"--sample_1_of_n_eval_examples\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/training\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_STEPS=1000\u001b[0m\n",
      "\u001b[34mSM_HP_PIPELINE_CONFIG_PATH=pipeline.config\u001b[0m\n",
      "\u001b[34mSM_HP_SAMPLE_1_OF_N_EVAL_EXAMPLES=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/bin/sh -c \"./run_training.sh --model_dir /opt/training --num_train_steps 1000 --pipeline_config_path pipeline.config --sample_1_of_n_eval_examples 1\"\u001b[0m\n",
      "\u001b[34m2023-05-20 18:52:53,029 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m===TRAINING THE MODEL==\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \u001b[0m\n",
      "\u001b[34mTensorFlow Addons (TFA) has ended development and introduction of new features.\u001b[0m\n",
      "\u001b[34mTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\u001b[0m\n",
      "\u001b[34mPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \u001b[0m\n",
      "\u001b[34mFor more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\u001b[0m\n",
      "\u001b[34mW0520 18:52:59.833880 139658535831360 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\u001b[0m\n",
      "\u001b[34mI0520 18:52:59.854119 139658535831360 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting train_steps: 1000\u001b[0m\n",
      "\u001b[34mI0520 18:52:59.857993 139658535831360 config_util.py:552] Maybe overwriting train_steps: 1000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI0520 18:52:59.858115 139658535831360 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mW0520 18:52:59.886961 139658535831360 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0520 18:52:59.895123 139658535831360 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0520 18:52:59.897099 139658535831360 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mI0520 18:52:59.897204 139658535831360 dataset_builder.py:80] Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW0520 18:52:59.905499 139658535831360 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW0520 18:52:59.927056 139658535831360 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW0520 18:53:07.208399 139658535831360 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34m`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\u001b[0m\n",
      "\u001b[34mW0520 18:53:10.275178 139658535831360 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34m`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0520 18:53:11.809314 139658535831360 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\u001b[0m\n",
      "\u001b[34mW0520 18:53:14.303176 139658535831360 module_wrapper.py:149] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI0520 18:53:20.710227 139653736818432 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0520 18:53:30.336383 139653736818432 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mW0520 18:53:39.429698 139654298838784 deprecation.py:569] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mI0520 18:53:40.671446 139654298838784 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0520 18:53:48.068610 139654298838784 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0520 18:53:55.134123 139654298838784 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0520 18:54:02.248498 139654298838784 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 100 per-step time 5.369s\u001b[0m\n",
      "\u001b[34mI0520 19:02:35.905617 139658535831360 model_lib_v2.py:705] Step 100 per-step time 5.369s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.26262408,\n",
      " 'Loss/localization_loss': 0.40678957,\n",
      " 'Loss/regularization_loss': 0.15145572,\n",
      " 'Loss/total_loss': 0.8208694,\n",
      " 'learning_rate': 0.0319994}\u001b[0m\n",
      "\u001b[34mI0520 19:02:35.905960 139658535831360 model_lib_v2.py:708] {'Loss/classification_loss': 0.26262408,\n",
      " 'Loss/localization_loss': 0.40678957,\n",
      " 'Loss/regularization_loss': 0.15145572,\n",
      " 'Loss/total_loss': 0.8208694,\n",
      " 'learning_rate': 0.0319994}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 200 per-step time 4.996s\u001b[0m\n",
      "\u001b[34mI0520 19:10:55.517919 139658535831360 model_lib_v2.py:705] Step 200 per-step time 4.996s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.29029265,\n",
      " 'Loss/localization_loss': 0.38774323,\n",
      " 'Loss/regularization_loss': 0.15145087,\n",
      " 'Loss/total_loss': 0.8294867,\n",
      " 'learning_rate': 0.0373328}\u001b[0m\n",
      "\u001b[34mI0520 19:10:55.518259 139658535831360 model_lib_v2.py:708] {'Loss/classification_loss': 0.29029265,\n",
      " 'Loss/localization_loss': 0.38774323,\n",
      " 'Loss/regularization_loss': 0.15145087,\n",
      " 'Loss/total_loss': 0.8294867,\n",
      " 'learning_rate': 0.0373328}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 300 per-step time 4.992s\u001b[0m\n",
      "\u001b[34mI0520 19:19:14.762479 139658535831360 model_lib_v2.py:705] Step 300 per-step time 4.992s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.21933071,\n",
      " 'Loss/localization_loss': 0.3461681,\n",
      " 'Loss/regularization_loss': 0.15139347,\n",
      " 'Loss/total_loss': 0.7168923,\n",
      " 'learning_rate': 0.0426662}\u001b[0m\n",
      "\u001b[34mI0520 19:19:14.762803 139658535831360 model_lib_v2.py:708] {'Loss/classification_loss': 0.21933071,\n",
      " 'Loss/localization_loss': 0.3461681,\n",
      " 'Loss/regularization_loss': 0.15139347,\n",
      " 'Loss/total_loss': 0.7168923,\n",
      " 'learning_rate': 0.0426662}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 400 per-step time 4.992s\u001b[0m\n",
      "\u001b[34mI0520 19:27:33.918236 139658535831360 model_lib_v2.py:705] Step 400 per-step time 4.992s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.21567427,\n",
      " 'Loss/localization_loss': 0.24238865,\n",
      " 'Loss/regularization_loss': 0.15133817,\n",
      " 'Loss/total_loss': 0.6094011,\n",
      " 'learning_rate': 0.047999598}\u001b[0m\n",
      "\u001b[34mI0520 19:27:33.918604 139658535831360 model_lib_v2.py:708] {'Loss/classification_loss': 0.21567427,\n",
      " 'Loss/localization_loss': 0.24238865,\n",
      " 'Loss/regularization_loss': 0.15133817,\n",
      " 'Loss/total_loss': 0.6094011,\n",
      " 'learning_rate': 0.047999598}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 500 per-step time 5.065s\u001b[0m\n",
      "\u001b[34mI0520 19:36:00.391688 139658535831360 model_lib_v2.py:705] Step 500 per-step time 5.065s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.17568927,\n",
      " 'Loss/localization_loss': 0.24358186,\n",
      " 'Loss/regularization_loss': 0.15119664,\n",
      " 'Loss/total_loss': 0.57046777,\n",
      " 'learning_rate': 0.053333}\u001b[0m\n",
      "\u001b[34mI0520 19:36:00.392070 139658535831360 model_lib_v2.py:708] {'Loss/classification_loss': 0.17568927,\n",
      " 'Loss/localization_loss': 0.24358186,\n",
      " 'Loss/regularization_loss': 0.15119664,\n",
      " 'Loss/total_loss': 0.57046777,\n",
      " 'learning_rate': 0.053333}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 600 per-step time 5.000s\u001b[0m\n",
      "\u001b[34mI0520 19:44:20.393965 139658535831360 model_lib_v2.py:705] Step 600 per-step time 5.000s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.21704356,\n",
      " 'Loss/localization_loss': 0.3503608,\n",
      " 'Loss/regularization_loss': 0.15116136,\n",
      " 'Loss/total_loss': 0.7185657,\n",
      " 'learning_rate': 0.0586664}\u001b[0m\n",
      "\u001b[34mI0520 19:44:20.394267 139658535831360 model_lib_v2.py:708] {'Loss/classification_loss': 0.21704356,\n",
      " 'Loss/localization_loss': 0.3503608,\n",
      " 'Loss/regularization_loss': 0.15116136,\n",
      " 'Loss/total_loss': 0.7185657,\n",
      " 'learning_rate': 0.0586664}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 700 per-step time 4.996s\u001b[0m\n",
      "\u001b[34mI0520 19:52:39.945817 139658535831360 model_lib_v2.py:705] Step 700 per-step time 4.996s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.27080292,\n",
      " 'Loss/localization_loss': 0.37136993,\n",
      " 'Loss/regularization_loss': 0.15115233,\n",
      " 'Loss/total_loss': 0.7933252,\n",
      " 'learning_rate': 0.0639998}\u001b[0m\n",
      "\u001b[34mI0520 19:52:39.946148 139658535831360 model_lib_v2.py:708] {'Loss/classification_loss': 0.27080292,\n",
      " 'Loss/localization_loss': 0.37136993,\n",
      " 'Loss/regularization_loss': 0.15115233,\n",
      " 'Loss/total_loss': 0.7933252,\n",
      " 'learning_rate': 0.0639998}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 800 per-step time 4.988s\u001b[0m\n",
      "\u001b[34mI0520 20:00:58.743552 139658535831360 model_lib_v2.py:705] Step 800 per-step time 4.988s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.25702032,\n",
      " 'Loss/localization_loss': 0.32483047,\n",
      " 'Loss/regularization_loss': 0.1510727,\n",
      " 'Loss/total_loss': 0.73292345,\n",
      " 'learning_rate': 0.069333196}\u001b[0m\n",
      "\u001b[34mI0520 20:00:58.743863 139658535831360 model_lib_v2.py:708] {'Loss/classification_loss': 0.25702032,\n",
      " 'Loss/localization_loss': 0.32483047,\n",
      " 'Loss/regularization_loss': 0.1510727,\n",
      " 'Loss/total_loss': 0.73292345,\n",
      " 'learning_rate': 0.069333196}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 900 per-step time 4.998s\u001b[0m\n",
      "\u001b[34mI0520 20:09:18.545425 139658535831360 model_lib_v2.py:705] Step 900 per-step time 4.998s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.20227706,\n",
      " 'Loss/localization_loss': 0.25761032,\n",
      " 'Loss/regularization_loss': 0.15095776,\n",
      " 'Loss/total_loss': 0.61084515,\n",
      " 'learning_rate': 0.074666604}\u001b[0m\n",
      "\u001b[34mI0520 20:09:18.545788 139658535831360 model_lib_v2.py:708] {'Loss/classification_loss': 0.20227706,\n",
      " 'Loss/localization_loss': 0.25761032,\n",
      " 'Loss/regularization_loss': 0.15095776,\n",
      " 'Loss/total_loss': 0.61084515,\n",
      " 'learning_rate': 0.074666604}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1000 per-step time 4.999s\u001b[0m\n",
      "\u001b[34mI0520 20:17:38.407866 139658535831360 model_lib_v2.py:705] Step 1000 per-step time 4.999s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.18398109,\n",
      " 'Loss/localization_loss': 0.24882978,\n",
      " 'Loss/regularization_loss': 0.15092072,\n",
      " 'Loss/total_loss': 0.5837316,\n",
      " 'learning_rate': 0.08}\u001b[0m\n",
      "\u001b[34mI0520 20:17:38.408190 139658535831360 model_lib_v2.py:708] {'Loss/classification_loss': 0.18398109,\n",
      " 'Loss/localization_loss': 0.24882978,\n",
      " 'Loss/regularization_loss': 0.15092072,\n",
      " 'Loss/total_loss': 0.5837316,\n",
      " 'learning_rate': 0.08}\u001b[0m\n",
      "\u001b[34m==EVALUATING THE MODEL==\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \u001b[0m\n",
      "\u001b[34mTensorFlow Addons (TFA) has ended development and introduction of new features.\u001b[0m\n",
      "\u001b[34mTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\u001b[0m\n",
      "\u001b[34mPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \u001b[0m\n",
      "\u001b[34mFor more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mW0520 20:17:45.127853 140350536431424 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mI0520 20:17:45.128057 140350536431424 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI0520 20:17:45.128181 140350536431424 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mI0520 20:17:45.128317 140350536431424 config_util.py:552] Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mW0520 20:17:45.128462 140350536431424 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0520 20:17:45.183886 140350536431424 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0520 20:17:45.185287 140350536431424 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mI0520 20:17:45.185411 140350536431424 dataset_builder.py:80] Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mW0520 20:17:45.185526 140350536431424 dataset_builder.py:86] num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:`shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mW0520 20:17:45.187815 140350536431424 dataset_builder.py:93] `shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW0520 20:17:45.189578 140350536431424 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW0520 20:17:45.209685 140350536431424 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW0520 20:17:49.307687 140350536431424 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0520 20:17:50.474770 140350536431424 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\u001b[0m\n",
      "\u001b[34mW0520 20:17:53.384325 140350536431424 module_wrapper.py:149] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI0520 20:17:53.384698 140350536431424 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Found new checkpoint at /opt/training/ckpt-2\u001b[0m\n",
      "\u001b[34mI0520 20:17:53.385271 140350536431424 checkpoint_utils.py:177] Found new checkpoint at /opt/training/ckpt-2\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI0520 20:17:59.345598 140350536431424 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0520 20:18:12.568986 140350536431424 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0520 20:18:16.964453 140350536431424 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 0\u001b[0m\n",
      "\u001b[34mI0520 20:18:16.990852 140350536431424 model_lib_v2.py:966] Finished eval step 0\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mW0520 20:18:17.132515 140350536431424 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 100\u001b[0m\n",
      "\u001b[34mI0520 20:18:33.746498 140350536431424 model_lib_v2.py:966] Finished eval step 100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 200\u001b[0m\n",
      "\u001b[34mI0520 20:18:46.721059 140350536431424 model_lib_v2.py:966] Finished eval step 200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mI0520 20:18:54.162485 140350536431424 coco_evaluation.py:293] Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mI0520 20:18:54.167515 140350536431424 coco_tools.py:116] Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:DONE (t=0.02s)\u001b[0m\n",
      "\u001b[34mI0520 20:18:54.183238 140350536431424 coco_tools.py:138] DONE (t=0.02s)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Eval metrics at step 1000\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.446700 140350536431424 model_lib_v2.py:1015] Eval metrics at step 1000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP: 0.076900\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.458251 140350536431424 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP: 0.076900\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.50IOU: 0.163225\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.459192 140350536431424 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.50IOU: 0.163225\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.75IOU: 0.063616\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.460090 140350536431424 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.75IOU: 0.063616\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (small): 0.027836\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.460997 140350536431424 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (small): 0.027836\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (medium): 0.291465\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.461885 140350536431424 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (medium): 0.291465\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (large): 0.384856\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.462770 140350536431424 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (large): 0.384856\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@1: 0.021525\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.463660 140350536431424 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@1: 0.021525\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@10: 0.082264\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.464584 140350536431424 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@10: 0.082264\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100: 0.119129\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.465472 140350536431424 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100: 0.119129\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (small): 0.061203\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.466360 140350536431424 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (small): 0.061203\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (medium): 0.412145\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.467245 140350536431424 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (medium): 0.412145\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (large): 0.423004\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.468168 140350536431424 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (large): 0.423004\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/localization_loss: 0.577830\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.468934 140350536431424 model_lib_v2.py:1018] #011+ Loss/localization_loss: 0.577830\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/classification_loss: 0.451780\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.469691 140350536431424 model_lib_v2.py:1018] #011+ Loss/classification_loss: 0.451780\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/regularization_loss: 0.150921\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.470437 140350536431424 model_lib_v2.py:1018] #011+ Loss/regularization_loss: 0.150921\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/total_loss: 1.180532\u001b[0m\n",
      "\u001b[34mI0520 20:19:04.471179 140350536431424 model_lib_v2.py:1018] #011+ Loss/total_loss: 1.180532\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI0520 20:22:53.485518 140350536431424 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mI0520 20:23:02.500794 140350536431424 checkpoint_utils.py:231] Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mRunning per image evaluation...\u001b[0m\n",
      "\u001b[34mEvaluate annotation type *bbox*\u001b[0m\n",
      "\u001b[34mDONE (t=9.97s).\u001b[0m\n",
      "\u001b[34mAccumulating evaluation results...\u001b[0m\n",
      "\u001b[34mDONE (t=0.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.291\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.022\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.082\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.423\u001b[0m\n",
      "\u001b[34m==EXPORTING THE MODEL==\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \u001b[0m\n",
      "\u001b[34mTensorFlow Addons (TFA) has ended development and introduction of new features.\u001b[0m\n",
      "\u001b[34mTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\u001b[0m\n",
      "\u001b[34mPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \u001b[0m\n",
      "\u001b[34mFor more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mW0520 20:23:07.255460 139897253439296 deprecation.py:641] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mI0520 20:23:11.918199 139897253439296 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0520 20:23:21.892894 139897253439296 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0520 20:23:26.392955 139897253439296 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f3bd8383460>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.086049 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f3bd8383460>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f3bd80d89d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.382961 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f3bd80d89d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac0bdd60>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.383176 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac0bdd60>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac0bd4c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.383355 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac0bd4c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f3bac0db490>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.383529 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f3bac0db490>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac0dbdc0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.383669 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac0dbdc0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac0dbd00>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.383796 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac0dbd00>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f3bac0db2b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.383932 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f3bac0db2b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac1161f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.384047 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac1161f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac047f10>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.384175 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac047f10>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f3bac047280>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.384329 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f3bac047280>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac047c10>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.384462 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac047c10>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac047520>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.384583 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac047520>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac109820>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.384709 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac109820>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac0dadc0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.384840 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac0dadc0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac0da8e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.384968 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac0da8e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac0da5b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.385087 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac0da5b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac3ccd90>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.385212 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac3ccd90>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac03a040>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.385329 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac03a040>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac03a940>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.385456 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac03a940>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac03aa60>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.385581 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac03aa60>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac1ef970>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.385693 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac1ef970>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac12cca0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.385820 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac12cca0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bd00d7c70>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.385926 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bd00d7c70>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac10d130>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.386042 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac10d130>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac10d460>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.386189 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac10d460>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac10d760>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.386309 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac10d760>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac10d9a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.386400 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac10d9a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac10d6a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.386519 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3bac10d6a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac0e4b80>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.386610 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3bac0e4b80>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b9617f250>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.386733 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b9617f250>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b96180400>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.386823 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b96180400>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b961804c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.386948 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b961804c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b961809d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.387173 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b961809d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b96180a90>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.387316 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b96180a90>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b96180fa0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.387442 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b96180fa0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b961850a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.387576 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b961850a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b9618c2b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.387698 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b9618c2b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b961a8850>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.387826 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b961a8850>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b961a8d60>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.387964 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b961a8d60>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b961a8e20>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.388104 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b961a8e20>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b96192370>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.388224 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b96192370>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b96192430>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.388357 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b96192430>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b96192940>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.388491 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3b96192940>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b96192a00>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0520 20:23:29.388625 139897253439296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3b96192a00>, because it is not built.\u001b[0m\n",
      "\n",
      "2023-05-20 20:24:03 Uploading - Uploading generated training model\u001b[34mW0520 20:23:49.295367 139897253439296 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI0520 20:23:56.718707 139897253439296 builder_impl.py:797] Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34mI0520 20:23:58.166095 139897253439296 config_util.py:253] Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34m2023-05-20 20:23:59,495 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-05-20 20:24:14 Completed - Training job completed\n",
      "Training seconds: 5677\n",
      "Billable seconds: 5677\n"
     ]
    }
   ],
   "source": [
    "tensorboard_output_config = sagemaker.debugger.TensorBoardOutputConfig(\n",
    "    s3_output_path=tensorboard_s3_prefix,\n",
    "    container_local_output_path='/opt/training/'\n",
    ")\n",
    "\n",
    "estimator = CustomFramework(\n",
    "    role=role,\n",
    "    image_uri=container,\n",
    "    entry_point='run_training.sh',\n",
    "    source_dir='source_dir/',\n",
    "    hyperparameters={\n",
    "        \"model_dir\": \"/opt/training\",\n",
    "        \"pipeline_config_path\": \"pipeline.config\",\n",
    "        \"num_train_steps\": \"1000\",    \n",
    "        \"sample_1_of_n_eval_examples\": \"1\"\n",
    "    },\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.2xlarge',\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    "    disable_profiler=True,\n",
    "    base_job_name='tf2-object-detection-MobNetV2'\n",
    ")\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84545881",
   "metadata": {},
   "source": [
    "You should be able to see your model training in the AWS webapp as shown below:\n",
    "![ECR Example](../data/example_trainings.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9844f25",
   "metadata": {},
   "source": [
    "## Improve on the intial model\n",
    "\n",
    "Most likely, this initial experiment did not yield optimal results. However, you can make multiple changes to the `pipeline.config` file to improve this model. One obvious change consists in improving the data augmentation strategy. The [`preprocessor.proto`](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto) file contains the different data augmentation method available in the Tf Object Detection API. Justify your choices of augmentations in the writeup.\n",
    "\n",
    "Keep in mind that the following are also available:\n",
    "* experiment with the optimizer: type of optimizer, learning rate, scheduler etc\n",
    "* experiment with the architecture. The Tf Object Detection API model zoo offers many architectures. Keep in mind that the pipeline.config file is unique for each architecture and you will have to edit it.\n",
    "* visualize results on the test frames using the `2_deploy_model` notebook available in this repository.\n",
    "\n",
    "In the cell below, write down all the different approaches you have experimented with, why you have chosen them and what you would have done if you had more time and resources. Justify your choices using the tensorboard visualizations (take screenshots and insert them in your writeup), the metrics on the evaluation set and the generated animation you have created with [this tool](../2_run_inference/2_deploy_model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b38568-825f-4793-8ff0-d65aca4e80ca",
   "metadata": {},
   "source": [
    "# your writeup goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469ec555-1c20-4e96-9114-545c43196434",
   "metadata": {},
   "source": [
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.077\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.163\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.064\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.028\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.291\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.385\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.022\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.082\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.119\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.423"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
